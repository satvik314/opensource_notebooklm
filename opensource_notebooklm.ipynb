{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lSzgEXw9F4X65qSSgOs47ejMGRDkbuZH?usp=sharing)"
      ],
      "metadata": {
        "id": "hboiaQUnxx6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open Source Implementation of NotebookLM\n",
        "\n",
        "- Open source alternative to Google's NotebookLM\n",
        "- Uses Deepseek-V3 for language understanding and generation\n",
        "- Integrates PlayHT for text-to-speech capabilities\n",
        "- Demonstrates interactive notebook-based AI assistance"
      ],
      "metadata": {
        "id": "QNXyjixrwiTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook by [Build Fast with AI](https://www.buildfastwithai.com/genai-course)"
      ],
      "metadata": {
        "id": "iWkvJYD-xVlr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnKUkFDXthcO",
        "outputId": "4072b441-1c52-466b-c7ed-14a33ad58351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/411.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU fal-client langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"FAL_KEY\"] = userdata.get('FAL_KEY')\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = userdata.get('OPENROUTER_API_KEY')"
      ],
      "metadata": {
        "id": "pBBXMSTKucUE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "def generate_podcast_transcript(topic):\n",
        "    # Modify this template as per your requirement!\n",
        "    podcast_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "      Create an engaging conversation between two speakers discussing the topic: {topic}\n",
        "\n",
        "      Requirements:\n",
        "      - Generate exactly 5 back-and-forth exchanges\n",
        "      - Make it natural and conversational\n",
        "      - Include specific details about the {topic}\n",
        "      - Each line should start with either \"Speaker 1:\" or \"Speaker 2:\"\n",
        "\n",
        "      Here's an example of the format (but create NEW content about {topic}, don't copy this example):\n",
        "      Speaker 1: [First speaker's line]\n",
        "      Speaker 2: [Second speaker's line]\n",
        "\n",
        "      The response of the each speaker should be at most 20 words. The conversation has to be insightful, engaging, explanatory, deep diving and educational.\n",
        "\n",
        "      It should be in the style of a podcast where one speaker slightly is more knowledgeable than the other.\n",
        "\n",
        "      You are allowed to write only in the below format. Just give the output in the below format in a single string. No additional delimiters.\n",
        "\n",
        "      The content should be explanatory, deep diving and educational.\n",
        "\n",
        "      Speaker 1: Hey, did you catch the game last night?\n",
        "      Speaker 2: Of course! What a matchâ€”it had me on the edge of my seat.\n",
        "      Speaker 1: Same here! That last-minute goal was unreal. Who's your MVP?\n",
        "      Speaker 2: Gotta be the goalie. Those saves were unbelievable.\n",
        "\n",
        "\n",
        "      Remember: Create completely new dialogue about {topic}, don't use the above example.\n",
        "      \"\"\")\n",
        "\n",
        "    # Initialize the ChatOpenAI model\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"deepseek/deepseek-chat\",\n",
        "        openai_api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
        "        openai_api_base=\"https://openrouter.ai/api/v1\"\n",
        "    )\n",
        "\n",
        "    # Create the chain\n",
        "    chain = podcast_template | llm\n",
        "\n",
        "    response = chain.invoke({\"topic\": topic})\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "2nnzdQQDqH8z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = generate_podcast_transcript(\"Quantum Random Walks\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEVhAuW1txhR",
        "outputId": "fa1a663a-9dd3-4365-ed1e-bb66a333f3b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaker 1: Have you heard about quantum random walks? Theyâ€™re like classical random walks but with a quantum twist.  \n",
            "Speaker 2: Yeah, but how do they differ? Classical walks spread linearly, right?  \n",
            "Speaker 1: Exactly! Quantum walks spread quadratically faster due to superposition and interference. Itâ€™s mind-blowing!  \n",
            "Speaker 2: So, does that mean theyâ€™re more efficient for algorithms?  \n",
            "Speaker 1: Absolutely! Theyâ€™re used in quantum search and optimization problems, outperforming classical methods.  \n",
            "Speaker 2: Thatâ€™s fascinating! How do they handle decoherence, though?  \n",
            "Speaker 1: Great question! Decoherence is a challenge, but error correction techniques help maintain quantum coherence.  \n",
            "Speaker 2: Makes sense. So, are quantum walks practical yet, or still theoretical?  \n",
            "Speaker 1: Mostly experimental, but progress is rapid. Theyâ€™re paving the way for quantum computing breakthroughs!  \n",
            "Speaker 2: Canâ€™t wait to see where this leads. Quantum walks sound like the future!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_podcast(topic):\n",
        "    print(f\"\\nğŸ™ï¸ Generating podcast transcript about: {topic}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Get transcript first using generate_podcast_transcript\n",
        "    transcript_result = generate_podcast_transcript(topic)\n",
        "\n",
        "    print(\"\\nâœï¸ Generated transcript:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(transcript_result)\n",
        "\n",
        "    print(\"\\nğŸ”Š Converting transcript to audio...\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Progress callback for fal-client\n",
        "    def on_queue_update(update):\n",
        "        if isinstance(update, fal_client.InProgress):\n",
        "            for log in update.logs:\n",
        "                print(f\"ğŸµ {log['message']}\")\n",
        "\n",
        "    # Generate audio using fal-client\n",
        "    try:\n",
        "        result = fal_client.subscribe(\n",
        "            \"fal-ai/playht/tts/ldm\",\n",
        "            {\n",
        "                \"input\": transcript_result,\n",
        "                \"voices\": [\n",
        "                    {\n",
        "                        \"voice\": \"Jennifer (English (US)/American)\",\n",
        "                        \"turn_prefix\": \"Speaker 1: \"\n",
        "                    },\n",
        "                    {\n",
        "                        \"voice\": \"Dexter (English (US)/American)\",\n",
        "                        \"turn_prefix\": \"Speaker 2: \"\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "            with_logs=True,\n",
        "            on_queue_update=on_queue_update,\n",
        "        )\n",
        "\n",
        "        print(\"\\nâœ… Audio generation complete!\")\n",
        "        print(f\"ğŸ”— Audio URL: {result['audio']['url']}\")\n",
        "\n",
        "        return {\n",
        "            \"conversation\": transcript_result,\n",
        "            \"audio_url\": result['audio']['url']\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Error generating audio: {str(e)}\")\n",
        "        return {\n",
        "            \"conversation\": transcript_result,\n",
        "            \"audio_url\": None,\n",
        "            \"error\": str(e)\n",
        "        }"
      ],
      "metadata": {
        "id": "ocPp1ws8wU-9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_podcast(\"Quantum Random Walks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3k81CQJwYjU",
        "outputId": "90cef993-6904-4b89-ecf2-a683dc4ad5a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ™ï¸ Generating podcast transcript about: Quantum Random Walks\n",
            "--------------------------------------------------\n",
            "\n",
            "âœï¸ Generated transcript:\n",
            "--------------------------------------------------\n",
            "Speaker 1: Have you heard about quantum random walks? Theyâ€™re like classical random walks but with quantum weirdness.  \n",
            "Speaker 2: Yeah, but instead of probabilities, they use amplitudes, right? Superposition makes it way more powerful.  \n",
            "Speaker 1: Exactly! The walker can explore multiple paths simultaneously, leading to faster spread than classical walks.  \n",
            "Speaker 2: Thatâ€™s why theyâ€™re used in quantum algorithms, like search problems. The speedup is mind-blowing.  \n",
            "Speaker 1: True! And the interference effects? They can amplify or cancel paths, making it a game-changer for computation.\n",
            "\n",
            "ğŸ”Š Converting transcript to audio...\n",
            "--------------------------------------------------\n",
            "\n",
            "âœ… Audio generation complete!\n",
            "ğŸ”— Audio URL: https://v3.fal.media/files/penguin/TencvNVwGMCgAXACDYIYn_de8c5432-cfb7-4b4b-9f40-e8c3b819674b.mp3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conversation': 'Speaker 1: Have you heard about quantum random walks? Theyâ€™re like classical random walks but with quantum weirdness.  \\nSpeaker 2: Yeah, but instead of probabilities, they use amplitudes, right? Superposition makes it way more powerful.  \\nSpeaker 1: Exactly! The walker can explore multiple paths simultaneously, leading to faster spread than classical walks.  \\nSpeaker 2: Thatâ€™s why theyâ€™re used in quantum algorithms, like search problems. The speedup is mind-blowing.  \\nSpeaker 1: True! And the interference effects? They can amplify or cancel paths, making it a game-changer for computation.',\n",
              " 'audio_url': 'https://v3.fal.media/files/penguin/TencvNVwGMCgAXACDYIYn_de8c5432-cfb7-4b4b-9f40-e8c3b819674b.mp3'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}